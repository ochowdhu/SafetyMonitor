\section{Introduction}
%Embedded systems, from home appliances to automobiles, are becoming increasingly complex due to the addition of new advanced features.
%It is paramount for these embedded systems, especially safety-critical systems (\eg, autonomous vehicles, aircraft flight control), to be formally verified to avoid catastrophic consequences of malfunctioning (\eg, loss of life, property damage) due to implementation errors or design flaws.
%% want to cover abstraction and scalability
%Static verification techniques such as model checking \cite{Clarke1996} and theorem proving \cite{Chang1997} can provide provable guarantees about system correctness, but scalability restrictions (\ie, the state-space explosion problem) and runtime failures beyond the scope of model abstractions \cite{Koopman2011} create the need for additional techniques.
%%Static verification techniques like model checking and theorem provers are applicable to obtain provable guarantees about the SC systems' correctness. However, model checking suffers from the state-space explosion problem whereas theorem provers require significant manual intervention.
Runtime verification (RV) is a promising alternative to its static counterparts (\eg, model checking \cite{Clarke1996} and theorem proving \cite{Chang1997})
for checking  safety and correctness properties of safety-critical embedded systems.
%in the face of increasing design complexity.
In RV, a runtime monitor observes the concrete execution of the system in question and checks for violations of some
%well-defined
stipulated
properties.
When the monitor detects a violation of a property, it notifies a command module which then attempts to recover from the violation. \emph{In this paper, we develop a runtime monitor that monitors an autonomous research vehicle (ARV) and describe our experience with it}.

The ARV is an autonomous heavy truck which is being designed for use in vehicle platoons. It is representative of common modern ground vehicle designs.
These systems are generally built by system integrators who utilize commercial-off-the-shelf  components, some of which may be provided as black-box systems,
developed from multiple vendors.
%The ARV system we consider are built by system integrators utilizing multiple vendors and commercial-off-the-shelf (COTS) components, some of which can be viewed as black box components for the integrator.
These systems are also often hard real-time systems which leads to additional constraints on system monitoring \cite{Goodloe2010}.
% instrumentation citations -- bonakdarpour2011 has some, but a little weak (gdb)
% bonakdarpour2011/2012 (2012 better) --  instrumentation is vital for enabling monitoring...
% chen2003 -- MoP paper, they instrument for both inline and offline (to get events out)
% havelund2002/2004 (2004 better)-- the system must be instrumented to emit execution events to the dispatcher
% Kim2004 -- MaC paper, also good for interface discussion
This type of system architecture is incompatible with many existing runtime monitoring techniques, which often require program or system instrumentation \cite{Havelund2004, Chen2003, Bonakdarpour2012,Kim2004} to obtain the relevant events or policy-constructs (\eg, propositions) necessary to check for violations.
Instrumenting systems without access to component source code is more difficult, and even when the source is available there are risks of affecting the timing and correctness of the target system when instrumented.

\noindent
\textit{Obtaining relevant policy constructs.}
To avoid instrumentation, we obtain the relevant information for monitoring the ARV system through passive observation of
its broadcast buses. % \cite{Rushby2001}.
Controller area network (CAN) is a
%common and
standard broadcast bus for ground vehicles which is the primary system bus in the ARV. We can obtain useful amounts of system state relevant information for monitoring
the system safety specification by observing the data within the CAN messages that are broadcasted between system components.
However, before we can start monitoring the ARV system, we need a component, which we call the \sfmap (in short, \emph{state to proposition}), that observes messages transmitted on the bus and decodes
them into propositions relevant to monitoring which are then fed into the monitor.
% This acts similarly to the low-level specification and filter/event recognizers from MaC \cite{Kim2004}.
We want to emphasize that the limits of external observability can cause significant challenges
in designing the \sfmap when considering the state available from the system messages and
the necessary atomic policy-constructs \cite{Kane2014}.
%We want to emphasize that depending on the granularity of the information available in the messages and the necessary atomic policy-constructs, developing the \textsf{SF Map} poses a significant challenge.

\noindent
\textit{Specification logic.}
To obtain the relevant safety requirements and invariants for monitoring the ARV system we consulted the safety requirements of the ARV system.
We observed that many desired properties for these types of systems are timing related, so using an explicit-time based specification language for expressing these properties is helpful.
System requirements like
 of the form ``\emph{the system must perform action $a$ within $t$ seconds of event $e$}'' are common,
 for instance,
``\emph{Cruise control shall disengage for 250ms within 500ms of the brake pedal being depressed}''.
%
For efficient monitoring, we use a fragment of propositional, discrete time metric temporal logic (MTL)\cite{Koymans1990} in which the
%bound
time constraint
associated with the future temporal operators must be finite. % classic cite, could go newer, thati2005 is close to ours

\noindent
\textit{Monitoring algorithm.}
We have developed a runtime monitoring algorithm, which we call \monitor, that incrementally takes as input a system state
(\ie, a state maps relevant propositions to either true/false) and a MTL formula and eagerly checks the state trace for violations.
Some of the existing monitoring algorithms that support bounded future formulas wait for the full-time of the bound before evaluating the formula (\eg, \cite{Basin2008}).
\monitor uses a dynamic programming based iterative algorithm that tries to reduce the input formula as soon as possible using history summarizing structures and straightforward formula-rewriting based simplifications when possible (leaving a partially reduced formula when future input is required).
This eager nature of the algorithm can detect a violation earlier leaving the system more time to attempt a graceful recovery.
We have also proved the correctness of our algorithm. As the target systems we envision to monitor
have strict time restriction,
it is possible that the eager checks
performed by \monitor are not finished before the next trace state arrives,
possibly corrupting \monitor's state. To overcome this,
we have developed a hybrid monitoring algorithm, \ha, that first performs conservative
checking like traditional runtime monitoring algorithms for MTL and performs eager check
if time permits.

\noindent
\textit{Empirical evaluation.}
We have implemented \monitor on an inexpensive embedded platform and empirically evaluated it against logs obtained from the testing of an ARV system using properties derived from its safety requirements.
\monitor has moderate monitoring overhead and detected several safety violations in our experimental evaluation.


%is a commonly used logic for specifying these types of properties, and a bounded-future fragment of MTL can be used to ensure efficient monitoring of useful system properties.
% talk about explicit time? real time? something in that vein

%% third paragraph -- contributions
%In this paper we present a real-time embedded monitor for safety-critical embedded systems with black-box COTS components (such as automobiles). Our monitoring algorithm \monitor is an dynamic programming based iterative algorithm which utilizes formula reduction (essentially rewriting) and history structures to system traces obtained from a target broadcast bus against a given safety policy. We have implemented this algorithm on an inexpensive embedded platform and present a case study using the monitor to perform real-time checking of replayed CAN logs from the robustness testing of an autonomous vehicle.

%% 15 pages in this format is so short...
%Due to space restrictions, we defer the correctness proof of \monitor and other details to a technical report \cite{TechReport}.
