%%%%% Algorithm section

\section{Monitoring Algorithm}
%% Why our algorithm... 
%%% MTL due to explicit time restrictions
%%% need real-time finite trace checking

In order to monitor distributed embedded systems we need an algorithm which can continuously check explicit time specifications over finite traces. This has led to our algorithm \monitor which is an iterative monitoring algorithm based on formula reduction (essentially formula-rewriting). 
%
\monitor checks specifications written in a future-bounded metric temporal logic. A large portion of safety specification rules for safety-critical embedded systems require explicit time bounds to ensure timely behavior, so a specification language with explicit time bounds is important. 

To constantly check that the target system is adhering to its specification, we must constantly check the specification against the current system trace. To constantly check the system efficiently, \monitor is an iterative algorithm, performing additional checking as each new trace step arrives.

%The monitoring algorithm is an aggressive, iterative algorithm based on formula reduction (essentially formula-rewriting) and a stored history structure to check whether a given formula satisfies or violates the target trace. 
%It is aggressive in that the algorithm attempts to check future-time temporal formulas as soon as possible rather than wait until an answer is guaranteed to be available (by combining short-circuiting and immediate checking of temporal subformulas).
%This is in contrast to many existing runtime monitoring algorithms which either are restricted to past time logics (in which there is no waiting) or only check properties after their available delay. % some aggressive future time algorithms exist but almost always dynamic programming so can't do windowed bounds
%The algorithm is iterative in that the history structure must be updated at each timestep in the trace in order. 

\subsection{Specification Logic}
In this section, we introduce our safety specification language for embedded systems, which we call \planguage. \planguage is based on \emph{propositional metric temporal logic} (MTL) \cite{}. 
The syntax of our bounded MTL variant \planguage is given below:

%The specification logic is a bounded, propositional metric temporal logic where the target propositions are from a set of atomic propositions provided by the system interface. These propositions are derived from the observable system state and represent system properties, for example, a proposition $speedLT40mph$ could state whether the vehicle speed is less than 40mph.


\(
\begin{array}{ccc}
\policy & ::=  & \true \mid p \mid \neg \policy \mid \policy_1\vee \policy_2\mid
\policy_1\since_{\interval}\policy_2 \mid \policy_1\until_{\interval}\policy_2\mid\yesterday_{\interval}\policy\mid \tomorrow_{\interval}\policy
\end{array}
\)

%Policy formulas are represented by $\psi$. Formulas can include both past time operators ($\since$, $\lastmtl$) and future time operators ($\Until$,$\nextmtl$). Each temporal operator has an associated time interval $\interval$ of the form $[lo,hi]$ where $lo,hi \in \mathbb{N}$ and $lo \leq hi$

We assume we are given a finite set of propositions, denoted by \cP, which can be used to specify safety policies. 
These propositions are generated by the system interface from observable system state.
Each proposition $p\in\cP$ is a formula of \planguage. 
We have logical connectives ($\neg, \vee$) and also have past ($\since, \yesterday$) and future ($\until, \tomorrow$) temporal operators. 
Each temporal operator has an interval (denoted by \interval) associated with it in which the formula is evaluated. 
The interval has the form $[lo, hi]$ where $lo, hi\in\mathbb{N}$ and $lo\leq hi$. 
The interval imposes an additional time interval constraint in which the immediate sub-formula must be true. 
For example, $\policy_1\since_{[lo, hi]}\policy_2$ is true at current time $t$ represents that $\policy_2$ was true in the past within times $t-hi$ to $t-lo$  and from that point on, $\policy_1$ has been true. 
For past temporal operators, we allow the high end point of \interval to be $\infty$. 
However, we require our \policy to be \emph{future bounded}, \ie, the high end-point of \interval associated with all future temporal operators must be finite and bounded. 
This restriction is necessary for the termination of our safety monitoring algorithm, as will be discussed later. 

\Paragraph{Derived Operators. }In our syntax, we present a minimal set of logical connectives and temporal operators. 
Other logical connectives and temporal operators can be derived using the following equivalences. (Logical false) $\false\equiv \neg \true$ . 
(Conjunction) $\policy_1\wedge\policy_2\equiv\neg(\neg\policy_1\vee\neg\policy_2)$. 
(Logical implication) $\policy_1\rightarrow\policy_2\equiv \neg\policy_1\vee\policy_2$. 
(Logical equivalence) $\policy_1\leftrightarrow\policy_2\equiv (\policy_1\rightarrow\policy_2)\wedge(\policy_2\rightarrow\policy_1)$. 
(Past temporal operator ``once'') $\once_{\interval}\policy\equiv (\true\since_{\interval}\policy)$. 
(Past temporal operator ``historically'') $\historically_{\interval}\policy\equiv \neg\once_{\interval}\neg\policy$. 
(Future temporal operator ``eventually'') $\eventually_{\interval}\policy\equiv (\true\until_{\interval}\policy)$. 
(Future temporal operator ``henceforth'') $\henceforth_{\interval}\policy\equiv \neg\eventually_{\interval}\neg\policy$. 


\Paragraph{Semantics. }\planguage formulas are interpreted over time-stamped \emph{traces}. A trace $\sigma$ is a sequence of states, each of which maps all propositions in \cP, to either \true or \false. We denote the $i^{th}$ position of the trace with $\sigma_i$ where $i\in\mathbb{N}$. Moreover, each $\sigma_i$ has an associated time stamp denoted by $\tau_i$ where $\tau_i\in\mathbb{N}$. 
We denote the sequence of time stamps with $\tau$. For all $i, j\in\mathbb{N}$ such that $i < j$, we require $\tau_i < \tau_j$. For a given trace $\sigma$ and time stamp sequence $\tau$, we write $\sigma, \tau, i\models\policy$ to denote that the formula \policy is true with respect to the $i^{th}$ position of $\sigma$ and $\tau$. We define $\sigma, \tau, i\models\policy$  inductively in the following way. 
\begin{itemize}
 \item $\sigma, \tau, i\models\true$
 \item $\sigma, \tau, i\models p$ $\Longleftrightarrow$ $\sigma_i(p) = \true$. 
 \item $\sigma, \tau, i\models\neg\policy$ $\Longleftrightarrow$ $\sigma, \tau, i \not\models\policy$. 
 \item $\sigma, \tau, i\models\policy_1\vee\policy_2$ $\Longleftrightarrow$ $\sigma, \tau, i\models\policy_1$ or $\sigma, \tau, i\models\policy_2$. 
 \item $\sigma, \tau, i\models\policy_1\since_{[lo, hi]}\policy_2$ $\Longleftrightarrow$ there exists a $k\leq i$ such that $lo\leq\tau_i-\tau_k\leq hi$ and $\sigma, \tau, k\models\policy_2$, and for all $j$ such that $k< j\leq i$, $\sigma, \tau, j\models\policy_1$ holds. 
 \item $\sigma, \tau, i\models\policy_1\until_{[lo, hi]}\policy_2$ $\Longleftrightarrow$ there exists a $k\geq i$ such that $lo\leq\tau_k-\tau_i\leq hi$ and $\sigma, \tau, k\models\policy_2$, and for all $j$ such that $i\leq j< k$, $\sigma, \tau, j\models\policy_1$ holds.
 z
 \item $\sigma, \tau, i\models\yesterday_{[lo, hi]}\policy$ $\Longleftrightarrow$ $i > 0$, $lo \leq (\tau_i-\tau_{i-1})\leq hi$, and $\sigma, \tau, i-1\models\policy$.
 \item $\sigma, \tau, i\models\tomorrow_{[lo, hi]}\policy$ $\Longleftrightarrow$ $lo \leq (\tau_{i+1}-\tau_{i})\leq hi$, and $\sigma, \tau, i+1\models\policy$. 
\end{itemize}


Our monitoring algorithm utilizes \emph{residues}, which are partially reduced (\ie, rewritten) policy formulas representing the remaining portion of a formula which could not be fully evaluated given the current trace. A residue $r^j_{\policy}$ is a tagged pair $\rpt{j}{\policyv}{\policy}$ where $j$ is a position in the trace. We use these residues to efficiently hold policy history for future time formulas which cannot be evaluated due to incomplete information.

Policy formulas have a wait delay $\wdelay(\policy)$ which defines an upper bound on the time duration necessary to guarantee complete information to evaluate the formula. Past and present-time formulas have no wait delay, since all trace steps necessary to evaluate them have already been seen by the monitor. Future time formulas have a delay based on their duration. The length $|\policy|$ of a policy $\policy$ is defined as the total number of subformula, (\ie, the number of nodes in the policy AST).

To evaluate \planguage policies, we need to save a limited amount of history state of child policies of temporal subformula within a policy. For example, given the policy $ACCCancelReq \rightarrow \eventually_{\interval} ACCOff \vee (ACCOn \since_{\interval} ACCCancelReq)$, $ACCOff$ is a child policy of the temporal formula $\eventually_{\interval}$ and $ACCOn$ and $ACCCancelReq$ are children of the temporal formula $ACCOn \since_{\interval} ACCCancelReq$. The monitor must store some history of these child policies in order to evaluate the parent policy.
The operation $\tempSub$ identifies all the children of temporal subformula of a policy.
%% might want to do a more abstract example to show recursiveness
%That is, for $\alpha\, \mathcal{U}_{[l,h]}\, \beta$ we need to save the history of $\alpha$ and $\beta$ (and if either of those are also a temporal formula then we need their history as well). 


%% maybe need formula length, storage delay, simplify\dots


\subsection{Monitoring Algorithm}
Our runtime monitoring algorithm \monitor takes as input a specification $\policy$ and monitors a growing trace, building history structures and reporting the specification violations as soon as they are detected. We summarize the relevant algorithm functions below:

\begin{description}
\item[$\monitor{}(\policy)$] is the top-level function. \\
\item[$\reduce(\sigma_i, \tau_i, \histSt{i}, \rpt{i}{\policy}{\policy})$] reduces the given residue based on the current state $(\sigma_i,\tau_i)$ and the history $\histSt{i}$.
\item[$\tempSub(\policy)$] identifies the sub-formulas which require a history structure to evaluate the policy $\policy$.
\item[$\incrS(\histst{i-1}, \histSt{i}, \sigma_i, \tau_i, i)$] updates the history structure $\histst{i-1}$ to step $i$ given the current trace and history state.
\end{description}




\subsubsection{Top-level monitoring algorithm}
The top-level monitoring algorithm \monitor is a sampling-based periodic monitor which uses history structures to store trace state for evaluating temporal subformulas. \emph{History structures} are lists of residues along with past-time markers for evaluating infinite past-time formulas. 
The algorithm checks the given policy $\policy$ periodically at every trace sample step. 
When the policy cannot be decided at a given step (\eg, it requires future state to evaluate), the remaining policy residue is saved in a history structure for evaluation in future steps when the state will be available.
The high level algorithm \monitor is shown in Figure \ref{fig:algorithm}. 

First, all the necessary history structures $\histst[\policyv]{ }$ are identified using $\tempSub(\policy)$ and initialized. 
Once these structures are identified, the monitoring loop begins.
%
In each step, all the history structures are updated with the new trace step. 
This is done in increasing formula size since larger formula can depend on the history of smaller formula (which may be their subformula).
%
Each structure is updated using $\incrS(\histst[\policyv]{i-1},\histSt[\policyv]{i}, \sigma_i, \tau_i, i)$ which adds a residue for the current trace step to the structure and reduces all the contained residues with the new step state. 
Then, the same procedure is performed for the top level policy that is being monitored -- the policy's structure is updated with $\incrS(\histst{i-1},\histSt{i},\sigma_i,\tau_i, i)$.
Once updated, this structure contains the evaluation of the top-level policy. The algorithm reports any identified policy violations (\ie, any $\false$ residues) before continuing to the next trace step.
%
We note that due to the recursive nature of the monitoring algorithm, the top-level policy is treated exactly the same as any temporal subformula would be (which follows from the fact that the top-level policy contains an implicit $\henceforth$). 
The history structures updates for the top-level policy are separated in the algorithm description for clarity only.
The only difference between the top-level policy and temporal subformula is that violations are reported for the top-level policy. 

\begin{figure}
\begin{algorithmic}[1]
%\STATE Recognize formulas for which we build structures
\STATE For all recognized formulas $\policyv \in \tempSub(\policy)$: $\histst[\policy_1]{-1} \leftarrow \emptyset$
\STATE $i \leftarrow 0$
\LOOP
\STATE Obtain next trace step $(\sigma_i, \tau_i)$ 
\FOR{every $\policyv \in \tempSub(\policy)$ in increasing size}
	\STATE $\histst[\policyv]{i} \leftarrow \incrS(\histst[\policyv]{i-1}, \histSt[\policyv]{i}, \sigma_i, \tau_i, i)$
\ENDFOR
\STATE $\histst{i} \leftarrow \incrS(\histst{i-1}, \histSt{i}, \sigma_i, \tau_i, i)$
%\FOR{all $\rp{j}{\bot} \in S^i_{\varphi}$}
\FOR{all $\rp{j}{\false} \in \histst{i}$}
\STATE \texttt{Report violation on $\sigma$ at position $j$}
\ENDFOR
\STATE $i \leftarrow i + 1$
\ENDLOOP
\end{algorithmic}
\caption{\monitor Algorithm}\label{fig:algorithm}
\end{figure}

\subsubsection{Reducing Residues}
\monitor works primarily by reducing policy residues down to truth values. Residues are reduced by the $\reduce(\sigma_i, \tau_i, \histSt{i}, \rpt{j}{\policyv}{\policy})$ function, which uses the current state $\sigma_i,\tau_i$ and the stored history in $\histSt{i}$ to rewrite the policy $\policyv$ to a reduced form, either a truth value or a new policy which will evaluate to the same truth value as the original. For past or present-time formulas, $\reduce()$ is able to return a truth value residue since all the necessary information to decide the policy is available in the history and current state. Future-time policies may be fully-reducable if enough state information is available. If a future-time policy cannot be reduced to a truth value, it is returned as a residue unchanged.

\subsubsection{Incrementing History Structures}
To evaluate past and future-time policies, we must correctly store trace history which can be looked up during a residue reduction. We store the trace history of a policy $\policyv$ in a history structure $\histst[\policyv]{}$. This history structure contains a list of residues for the number of steps required to evaluate the top-level policy. History structures are incremented by the $\incrS(\histst[\policyv]{i-1}, \histSt[\policyv]{i}, \sigma_i, \tau_i, i)$ function. This function takes the previous step's history structure $\histst[\policyv]{i-1}$ and the current state ($\sigma_i,\tau_i$, and the updated smaller history structures $\histSt[policyv]{i}$) and performs two actions:
%\begin{enumerate}
	1) Adds a residue for the current step $i$ to $\histst[policyv]{i-1}$ and
	2) Reduces all residues contained in $\histst[policyv]{i-1}$ with the current state.
%\end{enumerate}
Together, these two actions leave an updated history structure $\histst[policyv]{i}$ which has updated history information for all the required steps.

\subsection{Algorithm Properties}

The following theorem states that \monitor is correct and prompt (returns answers within a bounded delay). The theorem requires that the history structures $\histSt{i}$ be consistent at $i$ with respect to the trace $\sigma,\tau$. This means that the history structures contain the actual history of the trace up to step $i$. The algorithm provides this consistency itself if run iteratively from step $0$.

\begin{theorem}[Correctness and Promptness of \monitor]
For all $i \in \mathbb{N}$, all formula $\varphi$, all time stamp sequences $\tau$ and all traces $\sigma$ it is the case that (1) if $\rp{j}{\false} \in \histst{i}$ then $\sigma, \tau, j \nvDash \policy$ and if $\rp{j}{\true} \in \histst{i}$ then $\sigma, \tau, j \vDash \policy$ (Correctness) and (2) if $\tau_i - \tau_j \geq \wdelay(\policy)$ then if $\sigma, \tau, j \nvDash \policy$ then $\rp{j}{\false} \in \histst{i}$ and if $\sigma, \tau, j \vDash \policy$ then $\rp{j}{\true} \in \histst{i}$ (Promptness)
.
\end{theorem}
\textit{Proof.} By mutual induction on the policy formula $\policy$ and time step $i$. See \cite{TechPaper}

%%%%%%%%%%%%%%%%%%%%%%%%%%% REWRITE LINE %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%% REWRITE LINE %%%%%%%%%%%%%%%%%%%%%
